{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нелинейные методы снижения размерности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA с ядрами\n",
    "\n",
    "Так как PCA фактически работает не исходными признаками, а с матрицей их ковариаций, можно\n",
    "использовать для ее вычисления вместо скалярного произведения $\\langle x_i, x_j \\rangle$ произвольное\n",
    "ядро $K(x_i, x_j)$. Это будет соответствовать переходу в другое пространство, в котором\n",
    "наше предположение о линейности уже будет иметь смысл. Единственная проблема - непонятно, как\n",
    "подбирать ядро.\n",
    "\n",
    "Ниже приведены примеры объектов в исходном пространстве (похожие группы обозначены одним цветом\n",
    "для наглядности), и результат их трансформации в новые пространства (для разных ядер). Если результаты\n",
    "получаются линейно разделимыми - значит мы выбрали подходящее ядро."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.datasets import make_circles, make_moons, make_blobs\n",
    "\n",
    "def KPCA_show(X, y):\n",
    "    reds = y == 0\n",
    "    blues = y == 1\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    rows, cols = 2, 2\n",
    "    plt.subplot(rows, cols, 1)\n",
    "    plt.scatter(X[reds, 0], X[reds, 1], alpha=0.5, c='r')\n",
    "    plt.scatter(X[blues, 0], X[blues, 1], alpha=0.5, c='b')\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    kernels_params = [\n",
    "        dict(kernel='rbf', gamma=10),\n",
    "        dict(kernel='poly', gamma=10),\n",
    "        dict(kernel='cosine', gamma=10),\n",
    "    ]\n",
    "    \n",
    "    for i, p in enumerate(kernels_params):\n",
    "        dec = KernelPCA(**p)\n",
    "        X_transformed = dec.fit_transform(X)\n",
    "        \n",
    "        plt.subplot(rows, cols, i + 2)\n",
    "        plt.scatter(X_transformed[reds, 0], X_transformed[reds, 1], alpha=0.5, c='r')\n",
    "        plt.scatter(X_transformed[blues, 0], X_transformed[blues, 1], alpha=0.5, c='b')\n",
    "        ax = plt.gca()\n",
    "        ax.set_aspect('equal', adjustable='box')\n",
    "        \n",
    "np.random.seed(54242)\n",
    "KPCA_show(*make_circles(n_samples=1000, factor=0.2, noise=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(54242)\n",
    "KPCA_show(*make_moons(n_samples=1000, noise=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE\n",
    "\n",
    "Возьмем датасет MNIST и сделаем проекции в двумерное пространство с помощью PCA, LDA и t-SNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Authors: Fabian Pedregosa <fabian.pedregosa@inria.fr>\n",
    "#          Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#          Mathieu Blondel <mathieu@mblondel.org>\n",
    "#          Gael Varoquaux\n",
    "# License: BSD 3 clause (C) INRIA 2011\n",
    "\n",
    "print(__doc__)\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import offsetbox\n",
    "from sklearn import (manifold, datasets, decomposition, ensemble,\n",
    "                     discriminant_analysis, random_projection)\n",
    "\n",
    "digits = datasets.load_digits(n_class=6)\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "n_samples, n_features = X.shape\n",
    "n_neighbors = 30\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Scale and visualize the embedding vectors\n",
    "def plot_embedding(X, title=None):\n",
    "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
    "    X = (X - x_min) / (x_max - x_min)\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(111)\n",
    "    for i in range(X.shape[0]):\n",
    "        plt.text(X[i, 0], X[i, 1], str(digits.target[i]),\n",
    "                 color=plt.cm.Set1(y[i] / 10.),\n",
    "                 fontdict={'weight': 'bold', 'size': 9})\n",
    "\n",
    "    if hasattr(offsetbox, 'AnnotationBbox'):\n",
    "        # only print thumbnails with matplotlib > 1.0\n",
    "        shown_images = np.array([[1., 1.]])  # just something big\n",
    "        for i in range(digits.data.shape[0]):\n",
    "            dist = np.sum((X[i] - shown_images) ** 2, 1)\n",
    "            if np.min(dist) < 4e-3:\n",
    "                # don't show points that are too close\n",
    "                continue\n",
    "            shown_images = np.r_[shown_images, [X[i]]]\n",
    "            imagebox = offsetbox.AnnotationBbox(\n",
    "                offsetbox.OffsetImage(digits.images[i], cmap=plt.cm.gray_r),\n",
    "                X[i])\n",
    "            ax.add_artist(imagebox)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Plot images of the digits\n",
    "n_img_per_row = 20\n",
    "img = np.zeros((10 * n_img_per_row, 10 * n_img_per_row))\n",
    "for i in range(n_img_per_row):\n",
    "    ix = 10 * i + 1\n",
    "    for j in range(n_img_per_row):\n",
    "        iy = 10 * j + 1\n",
    "        img[ix:ix + 8, iy:iy + 8] = X[i * n_img_per_row + j].reshape((8, 8))\n",
    "\n",
    "plt.imshow(img, cmap=plt.cm.binary)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('A selection from the 64-dimensional digits dataset')\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Projection on to the first 2 principal components\n",
    "\n",
    "print(\"Computing PCA projection\")\n",
    "t0 = time()\n",
    "X_pca = decomposition.TruncatedSVD(n_components=2).fit_transform(X)\n",
    "plot_embedding(X_pca,\n",
    "               \"Principal Components projection of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# Projection on to the first 2 linear discriminant components\n",
    "\n",
    "print(\"Computing Linear Discriminant Analysis projection\")\n",
    "X2 = X.copy()\n",
    "X2.flat[::X.shape[1] + 1] += 0.01  # Make X invertible\n",
    "t0 = time()\n",
    "X_lda = discriminant_analysis.LinearDiscriminantAnalysis(n_components=2).fit_transform(X2, y)\n",
    "plot_embedding(X_lda,\n",
    "               \"Linear Discriminant projection of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "# t-SNE embedding of the digits dataset\n",
    "print(\"Computing t-SNE embedding\")\n",
    "tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "t0 = time()\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "plot_embedding(X_tsne,\n",
    "               \"t-SNE embedding of the digits (time %.2fs)\" %\n",
    "               (time() - t0))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме проекции в двумерное пространство мы, очевидно, получили кластеризацию чисел. То есть одним из приложений этих методов является кластеризация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На прошлом семинаре мы сравнивали различные способы *линейного* снижения размерности на примере датасета \"ирисы\". Сегодня мы сравним результаты PCA (линейный способ снижения размерности) с ядровой разновидностью PCA и с t-SNE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Внимание, конкурс! \n",
    "\n",
    "Сейчас вам предстоит поэкспериментировать с различными нелинейными методами снижения размерности в задаче \"ирисы\". Победит тот, кто получит наилучшее качество заданного классификатора после снижения размерности. Если несколько человек получат одинаковое наилучшее качество, то победителем считается тот, кто показал свое решение первым.\n",
    "\n",
    "Время на выполнение задания: 30 минут."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set(style='white')\n",
    "from sklearn import datasets\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Загрузим наши ирисы\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Заведём красивую трёхмерную картинку\n",
    "fig = plt.figure(1, figsize=(6, 5))\n",
    "plt.clf()\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "\n",
    "plt.cla()\n",
    "\n",
    "for name, label in [('Setosa', 0), ('Versicolour', 1), ('Virginica', 2)]:\n",
    "    ax.text3D(X[y == label, 0].mean(),\n",
    "              X[y == label, 1].mean() + 1.5,\n",
    "              X[y == label, 2].mean(), name,\n",
    "              horizontalalignment='center',\n",
    "              bbox=dict(alpha=.5, edgecolor='w', facecolor='w'))\n",
    "# Поменяем порядок цветов меток, чтобы они соответствовали правильному\n",
    "y_clr = np.choose(y, [1, 2, 0]).astype(np.float)\n",
    "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=y_clr, cmap=plt.cm.spectral)\n",
    "\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.w_zaxis.set_ticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Прогоним встроенный в sklearn PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_centered = X - X.mean(axis=0)\n",
    "pca.fit(X_centered)\n",
    "X_pca = pca.transform(X_centered)\n",
    "\n",
    "def plot_projection(X,y):\n",
    "    plt.plot(X[y == 0, 0], X[y == 0, 1], 'bo', label='Setosa')\n",
    "    plt.plot(X[y == 1, 0], X[y == 1, 1], 'go', label='Versicolour')\n",
    "    plt.plot(X[y == 2, 0], X[y == 2, 1], 'ro', label='Virginica')\n",
    "    plt.legend(loc=0);\n",
    "    plt.show()\n",
    "    \n",
    "plot_projection(X_pca,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на качество классификатора DecisionTree на исходных признаках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "def fit_predict(X, y):\n",
    "\n",
    "    # Повторим то же самое разбиение на валидацию и тренировочную выборку.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, \n",
    "                                                        stratify=y, \n",
    "                                                        random_state=42)\n",
    "\n",
    "    clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict_proba(X_test)\n",
    "    print('Accuracy: {:.5f}'.format(accuracy_score(y_test, \n",
    "                                                    preds.argmax(axis=1))))\n",
    "    \n",
    "fit_predict(X_pca,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь ваша очередь пробовать новые методы. Чем больше методов вы попробуете, тем больше шанс, что именно вы получите лучшее качество!\n",
    "\n",
    "Не забудьте попробовать следующие методы:\n",
    "\n",
    "a) t-SNE\n",
    "\n",
    "b) PCA с ядром\n",
    "\n",
    "c) Можете использовать LDA (линейный метод из прошлого семинара), хотя это не обязательно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код-заготовка для использования t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import manifold\n",
    "\n",
    "#init: 'random' or 'pca'\n",
    "#learning_rate может быть любым. Попробуйте такие learning_rate: 1, 10, 100, 0.1, 0.01, ... Экспериментируйте!\n",
    "\n",
    "tsne = manifold.TSNE(n_components=2, init=..., learning_rate=...)\n",
    "X_tsne = ...\n",
    "\n",
    "plot_projection(X_tsne,y)\n",
    "fit_predict(X_tsne,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код-заготовка для использования Kernel PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#виды ядер (kernel) вы можете найти в этом ноутбуке выше, gamma может быть любым числом. Подбирайте параметры!\n",
    "kpca = KernelPCA(n_components=2, kernel=..., gamma=...)\n",
    "X_kpca = ...\n",
    "\n",
    "#Не забудьте визуализировать новые признаки и вывести на экран качество алгоритма на этих признаках."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы.** Напишите, какой метод снижения размерности, на ваш взгляд, работает лучше всего в данной задаче? И почему так может происходить?\n",
    "\n",
    "Какое наилучшее качество вам удалось получить?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
